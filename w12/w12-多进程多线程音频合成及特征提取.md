# 多进程+多线程音频合成及特征提取

> 假设你是一个播客频道的制作人，现在你收集一些文字资料，想将其转为音频并发布。现按1和2实现两个类进行并行处理。

## 1.MultiThreadASR
>（参考ali_tts_wav.py，实现类MultiThreadASR）因为文字资料较多，为了加快速度，现在请你利用多线程技术，通过多个线程同时对多个文字材料（比如多个段落等）进行音频转换。注意，测试时每个线程负责的文本长度不用太长，可以只负责转一段或几句；另，输出文件的命名注意跟顺序相关，便于播放时组织顺序。

### 主要实现
类外函数t2v_save,通过大模型将文本转为音频并保存

```python
def t2v_save(part_text, i, voice_name):
    response = dashscope.audio.qwen_tts.SpeechSynthesizer.call(
    model = "qwen-tts",
    api_key = KEY,
    text = part_text,
    voice = voice_name,
    )
    
    audio_url = response.output.audio["url"]
    save_path = r'C:\Users\Huawei\Desktop\好一个大学\课内学习\大二下\ppppp数据分析\w12\test_audios\text_{}_{}.wav'.format(voice_name,i)  

    #通过网络下载文件
    try:
        response = requests.get(audio_url)
        response.raise_for_status()  # 检查请求是否成功
        with open(save_path, 'wb') as f:
            f.write(response.content)
        print(f"音频文件已保存至：{save_path}")
    except Exception as e:
        print(f"下载失败：{str(e)}")
```
MultiThreadASR类，继承Thread类，初始化可指定voice

```python
#多线程转换文本->音频
class MultiThreadASR(Thread):
    def __init__(self, text, i, voice_name):
        super().__init__()
        self.text = text #text是字符串列表
        self.i = i
        self.voice_name = voice_name ##Chelsie（女）Cherry（女） Ethan（男）Serena（女）

    def run(self):
        print(f'正在处理第{self.i + 1}句')
        t2v_save(self.text[self.i],self.i, self.voice_name)

```

### 测试

**测试文本**：

```
纯英文：Three passions, simply but overwhelmingly strong, have governed my life: the longing for love, the search for knowledge, and unbearable pity for the suffering of mankind. These passions, like great winds, have blown me hither and thither, in a wayward course, over a deep ocean of anguish, reaching to the very verge of despair.
纯中文：我志愿加入中国共产党,拥护党的纲领,遵守党的章程,履行党员义务,执行党的决定,严守党的纪律,保守党的秘密,对党忠诚,积极工作,为共产主义奋斗终身,随时准备为党和人民牺牲一切,永不叛党。
中英数混合：我是陈冠希呀，现在是2023年啊，我现在在LA啊，我遇到一些很坏很坏的人，一些gangster， you know？现在我需要你的帮助，微信转账300块，帮我回到香港，你懂我意思吗，我对你敬礼啊，Salute.Actually这个proposal是非常creative的，但是这个schedule来得及吗？consumer 可以accept吗？我concern的点但在这个power point 都没有被 discuss到实在有点 pity！我比较prefer能够用比较 detail的approach来 present这个 topic。
多音字：人要是行，干一行，行一行。一行行，行行行；要是不行，干一行，不行一行。一行不行，行行不行
基本读音覆盖：ABCDEFGHIJKLMNOPQRSTUVWXYZ1234567890
```
**代码**

```python
if __name__ == "__main__":
    #测试文本
    file_path = r'C:\Users\Huawei\Desktop\好一个大学\课内学习\大二下\ppppp数据分析\w12\test.txt'
    text = get_text(file_path)#get_text:file->text
    #print(text)
    num_len = len(text)
    voice_names = ['Chelsie','Cherry','Ethan','Serena']

    #测试MultiThreadASR
    voice_name = input() #Chelsie（女）Cherry（女） Ethan（男）Serena（女）
    if voice_name not in voice_names:
        print('名称无效')
        sys.exit()

    for i in range(num_len):
        thread = MultiThreadASR(text, i, voice_name)
        threads.append(thread)

    for thread in threads:
        thread.start()
    for thread in threads:
        thread.join()

```
**输出**
```python
Chelsie
正在处理第1句
正在处理第2句
正在处理第3句
正在处理第4句
正在处理第5句
音频文件已保存至：C:\Users\Huawei\Desktop\好一个大学\课内学习\大二下\ppppp数据分析\w12\test_audios\text_Chelsie_4.wav 
音频文件已保存至：C:\Users\Huawei\Desktop\好一个大学\课内学习\大二下\ppppp数据分析\w12\test_audios\text_Chelsie_3.wav 
音频文件已保存至：C:\Users\Huawei\Desktop\好一个大学\课内学习\大二下\ppppp数据分析\w12\test_audios\text_Chelsie_1.wav 
音频文件已保存至：C:\Users\Huawei\Desktop\好一个大学\课内学习\大二下\ppppp数据分析\w12\test_audios\text_Chelsie_0.wav 
音频文件已保存至：C:\Users\Huawei\Desktop\好一个大学\课内学习\大二下\ppppp数据分析\w12\test_audios\text_Chelsie_2.wav
```

**评价** #人工评判

数字表现一般，比如文本中的数字，2025年读为两千零二十五年，300块读为三零零；

多音字十分幽默，行行不行读为xingxing不xing，那确实有点不行

字母表完全没读，没听懂在读啥。似乎对于语义逻辑不连贯的句子很难读对

## MultiProcessVoiceFeature
> 2. (参考vt.py，实现类MultiProcessVoiceFeature) 利用多进程对大模型合成的音频文件计算声音特征，并比较不同文字或不同角色的声音特征有无区别。注意，可以用进程池或者进程执行器等来实现进程的管理。

**代码**

思路是calculate_fearture计算单个音频文件的特征，get_feature方法使用pool.map()，对每一个人声分配一个进程，对同一人声的文件计算平均特征。

使用pool.map（），必须保证方法可序列化。最初一直报错，原因是没有设置calculate_feature为静态方法（或者完全可以像t2v_save一样写在类的外面），在跨进程传递方法时因实例依赖问题导致序列化错误。
```python
#多进程计算音频特征
class MultiProcessVoiceFeature():
    def __init__(self, workers = None):
        self.workers = workers

    @staticmethod
    def calculate_feature(audio_file):
        '''
        计算单个音频的特征，返回平均值和连续时间'''
        y, sr = librosa.load(audio_file, sr = None)
        #音高
        pitch = librosa.yin(y,fmin = librosa.note_to_hz('C1'),fmax = librosa.note_to_hz('C7'))  
        avg_pitch = np.mean(pitch)
        #声强
        sdb = librosa.amplitude_to_db(librosa.feature.rms(y=y), ref=0.00002)
        avg_sdb = np.mean(sdb)
        #语速
        onsets = librosa.onset.onset_detect(y=y,sr=sr,units="time",hop_length=128,backtrack=False) 
        number_of_words = len(onsets)
        duration = len(y)/sr
        words_per_second = number_of_words/duration

        #以元组形式返回
        return (avg_pitch, avg_sdb, words_per_second, duration)

    def get_feature(self, audio_files):
        '''
        所有音频文件的加权平均
        '''
        with Pool(processes=self.workers) as pool:
            results = pool.map(self.calculate_feature, audio_files)

        # 提取各特征和持续时间
        pitches = [r[0] for r in results]
        sdbs = [r[1] for r in results]
        wpss = [r[2] for r in results]
        durations = [r[3] for r in results]
        total_duration = sum(durations)
        weights = np.array(durations)/total_duration

        # 加权平均（按 duration 加权）
        avg_pitch = np.average(pitches, weights=weights)
        avg_sdb = np.average(sdbs, weights=weights)
        avg_words_per_second = np.average(wpss,weights=weights)

        return (avg_pitch, avg_sdb, avg_words_per_second)
```
**测试**

指定进程为4
```python
#测试MultiProcessVoiceFeature
    #每种声音都转成音频
    '''
    for voice_name in voice_names:
        threads = []
        for i in range(num_len):
            thread = MultiThreadASR(text, i, voice_name)
            threads.append(thread)
        for thread in threads:
            thread.start()
        for thread in threads:
            thread.join()
            '''
    
    #用字典记录音频文件、音频特征
    voice_file_dic = {voice_name:[] for voice_name in voice_names}
    voice_feature_dic = {voice_name:None for voice_name in voice_names}

    dir_path = r'C:\Users\Huawei\Desktop\好一个大学\课内学习\大二下\ppppp数据分析\w12\test_audios'

    # 初始化特征处理器
    feature_processor = MultiProcessVoiceFeature(workers=4)
    
    # 计算特征
    for voice_name in voice_names:
        audio_files = [os.path.join(dir_path, f'text_{voice_name}_{i}.wav') for i in range(num_len)]
        features = feature_processor.get_feature(audio_files)
        voice_feature_dic[voice_name] = features
        print(f"{voice_name} 特征: 平均音高={features[0]:.2f}Hz, "
              f"平均声强={features[1]:.2f}dB, 平均语速={features[2]:.2f}词/秒")

```
**输出**

和人耳听感大致相符

```python
Chelsie 特征: 平均音高=456.20Hz, 平均声强=61.69dB, 平均语速=3.33词/秒
Cherry 特征: 平均音高=450.79Hz, 平均声强=60.64dB, 平均语速=3.98词/秒
Ethan 特征: 平均音高=259.31Hz, 平均声强=60.01dB, 平均语速=3.37词/秒
Serena 特征: 平均音高=400.58Hz, 平均声强=60.12dB, 平均语速=4.53词/秒
```


> 3. （附加）有余暇的同学建议根据kokoro_readme.txt等在本地部署kokoro，并利用其来合成声音（可参考kokoro_tts_zh.py)。由于在本地运行，因此可以用来对大规模文本进行语音合成，如进行小说阅读或其他。
