# LDAä¸»é¢˜æ¨¡å‹
## æ–‡æ¡£é¢„å¤„ç†

> ä¸€èˆ¬æ¥è®²ï¼ŒLDAåœ¨è¯„è®ºç­‰çŸ­æ–‡æœ¬ä¸Šçš„æ•ˆæœå¹¶ä¸ç†æƒ³ï¼Œä¸”å¤šæ•°æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å¸Œæœ›ç»™è¯é¢˜èµ‹äºˆæ—¶é—´å«ä¹‰ï¼Œä»¥è®¨è®ºå…¶â€œæ³¢åŠ¨æ€§â€ã€‚å› æ­¤ï¼Œå¾€å¾€å…ˆéœ€è¦æŒ‰æ—¶é—´è¿›è¡Œæ–‡æ¡£çš„ç”Ÿæˆï¼Œæ¯”å¦‚ï¼Œå°†æŸä¸€åº—é“ºçš„è¯„è®ºæŒ‰å¹´è¿›è¡Œåˆå¹¶ï¼Œå³å°†æŸåº—é“ºæŸå¹´å‘å¸ƒçš„æ‰€æœ‰è¯„è®ºè§†ä¸ºä¸€ä¸ªæ–‡æ¡£ã€‚è¯·å®ç°ä¸€ä¸ªæ¨¡å—ï¼Œå…¶ä¸­åŒ…å«ä¸€ä¸ªæˆ–å¤šä¸ªå‡½æ•°ï¼Œå…¶èƒ½å¤Ÿè¯»å–è¯¥æ•°æ®é›†å¹¶å°†ä¹‹åˆ†åº—é“ºï¼ˆå…±8å®¶åº—é“ºï¼Œå¯æ ¹æ®shopIDè¿›è¡ŒåŒºåˆ†ï¼‰å¤„ç†ä»¥å¤©ï¼ˆæˆ–å…¶ä»–æ—¶é—´å•ä½ï¼‰ä¸ºå•ä½çš„æ–‡æ¡£é›†åˆã€‚

### æ€è·¯
æ–°å»ºpythonæ–‡ä»¶dfcut.py,ä¿å­˜åœ¨ä¸»æ–‡ä»¶åŒä¸€æ–‡ä»¶å¤¹ä¸­ã€‚å®šä¹‰å‡½æ•°id_time_cut(file_path, shopid, TimeMode),è¯»å–æ–‡ä»¶ï¼Œæ ¹æ®åº—é“ºIDå’ŒTimeModeç­›é€‰å­è¡¨ï¼Œåˆå¹¶åŒä¸€æ—¶é—´æ–‡æœ¬ï¼Œè¿”å›ä¸€ä¸ªå­—å…¸ã€‚å…¶ä¸­keyä¸ºæ—¶é—´å€¼ï¼Œvalueä¸ºå­—ç¬¦ä¸²åˆ—è¡¨ã€‚

### ä»£ç 
```Python
import pandas as pd
#import os

def id_time_cut(file_path, shopid, TimeMode) -> dict:
    '''å°†æŸä¸€åº—é“ºçš„è¯„è®ºæŒ‰{TimeMode}è¿›è¡Œåˆå¹¶
    è¿”å›å­—å…¸{æ—¶é—´ï¼šlistæ–‡æ¡£}'''
    
    df = pd.read_csv(file_path, encoding='gbk')
    sub_df = df[df['shopID'] == shopid]
    sub_df = sub_df[['cus_comment', TimeMode]]
    text_at_time_dic = {}
    
    #éå†æ¯è¡Œ
    for index,row in sub_df.iterrows():
        time = row[TimeMode]
        comment = row['cus_comment']
        if pd.isnull(comment):  #å»é™¤ç©ºç™½è¯
            continue
        
        if time not in text_at_time_dic:
            text_at_time_dic[time] = []

        text_at_time_dic[time].append(comment)


    return text_at_time_dic
```

### è¾“å‡º
```Python
['åŒçš®å¥¶ å¥½å‘³ æ¯”ä»ä¿¡ å¤§ç¢— äº‘åé¢ å¥½ å¤§ç¢— æŠµé£Ÿ ä¸è¿‡ å¤ªå¤šäºº é˜¿å§¨ éƒ½ å¾ å¤šç† äºº', 'åŒçš®å¥¶ å¾ˆ å¥½åƒ çš„ ä¸è¿‡ ç¯å¢ƒ å¤ª åµ æ‚ äº† è¦ å’Œ äºº æ‹¼æ¡Œ çš„ è¯´', 'é›™çš®å¥¶ æ˜¯ æˆ‘ çš„ è‡³ æ„›å¿… åƒ  è¿™ è£¹ åƒ¹éŒ¢ å¯ä»¥ é›™çš®å¥¶ åš çš„ æ¯”ä»ä¿¡ å¥½', 'åŒçš®å¥¶ æ¯”ä»ä¿¡  å¥½ å¾ˆå¤š å°±æ˜¯ å¤ªæŒ¤ äº† æœåŠ¡ å°± æœ‰ç‚¹ è·Ÿä¸ä¸Š å’¯ æ€»ä½“ é£Ÿç‰© æ°´ å¹³ ä¸é”™', 'æŒ¤å¾— ä¸€å¡Œç³Šæ¶‚ åªèƒ½ æ‹¼æ¡Œ æœåŠ¡å‘˜ å¤§å–Šå¤§å« è·‘æ¥è·‘å» å®Œå…¨ ä¸§å¤± äº† å“ä½ ç¾é£Ÿ çš„ å…´è‡´ å°è±¡ æ‰“ äº† å¤§å¤§çš„ æŠ˜æ‰£ ä¸»é£Ÿ å“ç§ æ¯” ç”œç‚¹ è¿˜ å¤š è™½ç„¶ ä»·æ ¼ æ›´åŠ  çš„ ä¾¿å®œ åæ°” ä¹Ÿ å¾ˆ å“äº® ä½† åŒçš®å¥¶ å’Œ å…¶ä»– ç”œæ°´ ä» å¤–è¡¨ æ¥è¯´ å°± ä¸åŠ ä»ä¿¡ ä¸€å° æ›´æ˜¯ ç”œ çš„ å‘è…» ç‰¹åˆ« æ˜¯ å¥¶ç³Š ç»å¯¹ è‚¥', 'åç”«è·¯ çš„ åº—  ç”Ÿæ„ çœŸçš„ çˆ†å¥½ å¹³å¿ƒè€Œè®º è¿™é‡Œ çš„ åŒçš®å¥¶ è¿˜ ä¸é”™ æ›¾ç» æ˜¯ å°è±¡ ä¸­ çš„ ç¬¬ä¸€å ç›´åˆ° åœ¨ é¦™æ¸¯ åƒ åˆ°ç›Š é¡ºäºº çš„ å˜´ çœŸå® åˆ  å•Š', 'æœ€ æç¬‘ çš„ æ˜¯ æˆ‘ æŠŠ å•å­ å¼„ ä¸¢ äº† å·®ç‚¹ å°± æŠŠ ç«¯ åˆ° æˆ‘ é¢å‰ çš„ åŒçš®å¥¶ ç»™ ç«¯ å›å» å¯èƒ½ æ˜¯ å…ˆå…¥ä¸ºä¸» å§ è€Œä¸” åˆ° è¿™é‡Œ è¦ çš„ æ˜¯ çº¯ çš„ åŒçš®å¥¶ æ²¡åŠ  çº¢è±† è¡¨é¢ çš„ è£‚ç—• å°± ä¸å¯ é®æ© åœ°éœ² äº† å‡ºæ¥ æ„Ÿè§‰ æ•´ä½“ ä¸Š æ¯”ä»ä¿¡ çš„ å† å†» ä¸€ç‚¹ ä½†æ˜¯ çš® å°± æ²¡æœ‰ åšå‡º å‡¤å‡° å¥¶ç³Š å¥½ ç”œ å•Š å°±æ˜¯ å¥¶ç²‰ å†² çš„ æ„Ÿè§‰ ç¬¬å ç”« çš„ å°åƒ å¤ªå¤š äº† æ„Ÿè§‰ èƒƒå£ å®Œå…¨ è£…ä¸ä¸‹ å‘€ æ¯æ¬¡ æƒ³ åƒ äº‘åé¢ éƒ½ æ²¡ åœ°æ–¹ æ”¾ äº†', 'éå¸¸ å¥½åƒ æ¯æ¬¡ å» å¹¿å· éƒ½  è¦ æƒ³ åŠæ³• å» å°å° å°¤å…¶ æ˜¯ å‡¤å‡° å¥¶ç³Š ä¸€çº§ æ£’', 'ä¹Ÿ æ˜¯ ä¸ª è€å­—å· ç‚¹ äº† æ‹›ç‰Œ çš„ åŒçš®å¥¶ æƒ³ å°å° æ­£å®— çš„ å‘³é“ å¦‚ä½• å¯ èƒ½ æ˜¯ å¤©ç”Ÿ ä¸ å–œæ¬¢ è¿™ç§ å‘³é“ çš„ å§ åƒ äº† å‡ å£ å°± æµªè´¹ äº†', 'æœ€ å–œæ¬¢ è¿™é‡Œ çš„ å§œ åŸ‹å¥¶ å…¶ä»– ä¸»é£Ÿ ä¹Ÿ å¾ˆ ä¸é”™ å¦‚ç‰› ä¸‰æ˜Ÿ ä¸ªäºº è®¤ä¸º æ˜¯ å¹¿å· æœ€ å¥½åƒ çš„ äº‘åé¢ ä¹Ÿ å¾ˆ å¥½ å—é’± å°± æœ‰ å¤§å¤§çš„ è™¾ åœ¨ é‡Œé¢']
```
> ç¿»ä¸åˆ°æœ€å¼€å§‹printå‡ºæ¥çš„ä¸œè¥¿äº†ï¼ˆğŸ‘‰ğŸ»ğŸ‘ˆğŸ»ï¼‰...å­—ç¬¦ä¸²åˆ—è¡¨å¤§æ¦‚é•¿è¿™æ ·

## æ–‡æœ¬çš„ç‰¹å¾è¡¨ç¤º
> å®ç°ä¸€ä¸ªæ¨¡å—ï¼Œé€šè¿‡ä¸€ä¸ªæˆ–å¤šä¸ªå‡½æ•°ï¼Œå°†æ¯ä¸ªæ–‡æ¡£è½¬å˜ä¸ºè¯é¢‘ç‰¹å¾è¡¨ç¤ºï¼Œä»¥å½¢æˆæ–‡æ¡£-è¯è¯­çš„è¯é¢‘çŸ©é˜µï¼Œå¯ä»¥é€‰æ‹©ä½¿ç”¨sklearnä¸­çš„CountVectorizerå’ŒTfidfVectorizerä¸¤ç§æ–¹å¼ã€‚ä¹Ÿå¯ä»¥ä½¿ç”¨gensimä¸­çš„dictionary.doc2bowç­‰ã€‚

### æ€è·¯
è¿™é‡Œä½¿ç”¨äº†sklearnåº“çš„CountVectorizerã€‚æ–°å»ºDocToBow.pyæ–‡ä»¶ï¼Œä¿å­˜åœ¨ä¸»æ–‡ä»¶åŒä¸€æ–‡ä»¶å¤¹ä¸‹ã€‚å®šä¹‰Doc2Bowå‡½æ•°,è¾“å…¥id_time_cutè¿”å›çš„{æ—¶é—´ï¼šå­—ç¬¦ä¸²åˆ—è¡¨}å­—å…¸ï¼Œè¿”å›{æ—¶é—´ï¼šçŸ©é˜µ}å­—å…¸

### ä»£ç 
 ```Python
from sklearn.feature_extraction.text import CountVectorizer
import pandas as pd

def Doc2Bow(text_at_time_dic) -> dict:
    '''return {time:è¯é¢‘çŸ©é˜µ} '''
    matrix_at_time_dic = {}
    for time, doc in text_at_time_dic.items():
        vectorizer = CountVectorizer()
        matrix = vectorizer.fit_transform(doc)
        matrix_at_time_dic[time] = matrix
    return matrix_at_time_dic
```
### è¾“å‡º

## æ ¹æ®å›°æƒ‘åº¦é€‰å–æœ€ä¼˜è¯é¢˜æ•°
> è¶…å‚æ•°kï¼ˆå³è¯é¢˜çš„æ•°ç›®ï¼‰å˜åŒ–æ—¶ï¼Œè¯„ä»·LDAæ¨¡å‹çš„ä¸€ä¸ªæŒ‡æ ‡å³å›°æƒ‘åº¦ï¼ˆlda.perplexityï¼‰ä¼šéšä¹‹æ³¢åŠ¨ï¼Œå°è¯•ç»˜åˆ¶å›°æƒ‘åº¦éšè¯é¢˜æ•°ç›®kå˜åŒ–çš„æ›²çº¿ï¼Œæ‰¾åˆ°è¾ƒä¼˜çš„kã€‚

### æ€è·¯
å…ˆä»doc_at_time_dicä¸­æŠŠæ‰€æœ‰å­—ç¬¦ä¸²åˆ—è¡¨æå–å‡ºæ¥ï¼Œåˆå¹¶ä¸ºdocsï¼Œç»˜åˆ¶å›°æƒ‘åº¦éšè¯é¢˜æ•°ç›®å˜åŒ–çš„æ›²çº¿ï¼Œç†æƒ³çš„kå€¼åº”è¯¥æ˜¯ï¼šåœ¨kå‰æ›²çº¿é€æ¸ä¸‹é™ï¼Œkåè¶‹äºå¹³ç¨³

### ä»£ç 
```python
#ä¸ºæ‰¾åˆ°å›°æƒ‘åº¦ å…ˆæŠŠæ‰€æœ‰docæå–å‡ºæ¥
docs = []
for time,doc in doc_at_time_dic.items():
    docs += doc


vectorizer = CountVectorizer()
X = vectorizer.fit_transform(docs)

perplexity_scores = []
k_range = range(5,51,5) # kçš„èŒƒå›´
for k in k_range:
    lda = LatentDirichletAllocation(n_components=k,max_iter= 2000)
    lda.fit(X)
    perplexity_scores.append(lda.perplexity(X))
plt.plot(k_range, perplexity_scores, '-o')
plt.xlabel('Number of topics')
plt.ylabel('Perplexity')
plt.show()
```
### è¾“å‡º
è¿™ä¸€æ­¥åšäº†å‡ æ¬¡è°ƒå‚æœ€åç»“æœè¿˜æ˜¯ä¸å¥½çœ‹...æˆªæ­¢æˆ‘å†™æŠ¥å‘Šçš„æ—¶é—´ï¼ˆ2025å¹´3æœˆ24æ—¥14:45:14ï¼‰ï¼Œä¾æ—§æ²¡æœ‰è·‘å‡ºå¥½çš„ç»“æœï¼Œå…ˆæŠŠk_range = range(11), max_iter = 1000çš„ç»“æœæ”¾å‡ºæ¥å ä¸ªå‘......å¸Œæœ›åŠ©æ•™æ£€æŸ¥ä½œä¸šçš„æ—¶å€™æˆ‘å·²ç»è·‘å‡ºæ¥äº†ğŸ¥²ğŸ¥²ğŸ¥²
